{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        \n",
    "        self.x_data = x_data # torch.floattensor로 들어옴\n",
    "        self.y_data = y_data#.view(-1,1) # torch.longtensor로 들어옴\n",
    "        self.transform = transform\n",
    "        self.len = len(y_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample) #self.transform이 None이 아니라면 전처리를 작업한다.\n",
    "        \n",
    "        return sample \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len       \n",
    "\n",
    "class TrainTransform:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        #labels = labels.float()\n",
    "\n",
    "        transf = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "        final_output = transf(inputs)      \n",
    "        \n",
    "        return final_output, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subset(data, labels, num_cls, num_data): # numpy\n",
    "    num_data_per_class = num_data // num_cls\n",
    "    data1 = torch.tensor([],dtype=torch.float)\n",
    "    data2 = torch.tensor([],dtype=torch.float)\n",
    "    labels1 = torch.tensor([],dtype=torch.long)\n",
    "    labels2 = torch.tensor([],dtype=torch.long)\n",
    "    for cls in range(num_cls):\n",
    "        idx = np.where(labels.numpy() == cls)[0]\n",
    "        shuffled_idx = np.random.choice(len(idx), len(idx), replace=False)\n",
    "        data1 = torch.cat([data1, data[shuffled_idx[:num_data_per_class]]], dim=0)\n",
    "        data2 = torch.cat([data2, data[shuffled_idx[num_data_per_class:]]], dim=0)     \n",
    "        labels1 = torch.cat([labels1, labels[shuffled_idx[:num_data_per_class]]], dim=0)\n",
    "        labels2 = torch.cat([labels2, labels[shuffled_idx[num_data_per_class:]]], dim=0)\n",
    "\n",
    "    return data1, data2, labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 9867267.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 8100823.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True) # 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data, unlabeled_data, labels, unlabels = balanced_subset(trainset.data, trainset.targets, num_cls=10, num_data=2000)\n",
    "train_images, val_images, train_labels, val_labels = balanced_subset(labeled_data, labels, num_cls=10, num_data=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 28, 28]),\n",
       " torch.Size([58000, 28, 28]),\n",
       " tensor([6, 7, 8,  ..., 5, 4, 1]),\n",
       " tensor([5, 6, 0,  ..., 9, 2, 9]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.shape, unlabeled_data.shape, labels, unlabels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.unsqueeze(1)\n",
    "val_images = val_images.unsqueeze(1)\n",
    "trainset = MyDataset(train_images, train_labels, transform=TrainTransform())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)       \n",
    "validationset = MyDataset(val_images, val_labels)\n",
    "valloader = torch.utils.data.DataLoader(validationset, batch_size=128, shuffle=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_images = unlabeled_data.unsqueeze(1)\n",
    "unlabeledset = MyDataset(unlabeled_images, unlabels)\n",
    "unlabeledloader = torch.utils.data.DataLoader(unlabeledset, batch_size=256, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 및 전처리 작업\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "                        nn.Conv2d(1, 64, 3), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2),\n",
    "                        nn.Conv2d(64, 192, 3, padding=1), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2))       \n",
    "        self.classifier = nn.Sequential(\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(192*6*6, 1024), nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(1024, 512), nn.ReLU(),\n",
    "                        nn.Linear(512, 10))          \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 192*6*6)\n",
    "        x = self.classifier(x)    \n",
    "        return x\n",
    "\n",
    "model = Net().to(device) # 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 26, 26]             640\n",
      "              ReLU-2           [-1, 64, 26, 26]               0\n",
      "         MaxPool2d-3           [-1, 64, 13, 13]               0\n",
      "            Conv2d-4          [-1, 192, 13, 13]         110,784\n",
      "              ReLU-5          [-1, 192, 13, 13]               0\n",
      "         MaxPool2d-6            [-1, 192, 6, 6]               0\n",
      "           Dropout-7                 [-1, 6912]               0\n",
      "            Linear-8                 [-1, 1024]       7,078,912\n",
      "              ReLU-9                 [-1, 1024]               0\n",
      "          Dropout-10                 [-1, 1024]               0\n",
      "           Linear-11                  [-1, 512]         524,800\n",
      "             ReLU-12                  [-1, 512]               0\n",
      "           Linear-13                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 7,720,266\n",
      "Trainable params: 7,720,266\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.37\n",
      "Params size (MB): 29.45\n",
      "Estimated Total Size (MB): 30.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,200], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)       \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)      \n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전통적인 지도 학습(일반적인 분류) 방식\n",
    "1. 오직 레이블이 있는 데이터만 사용하여 모델을 훈련\n",
    "2. 훈련 중에 검증 데이터에 대한 정확도를 모니터링하며, 가장 높은 정확도를 달성한 경우 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 13.40, validation acc: 13.40 - Saved the best model\n",
      "[1] train acc: 23.30, validation acc: 46.00 - Saved the best model\n",
      "[2] train acc: 44.00, validation acc: 52.90 - Saved the best model\n",
      "[3] train acc: 53.00, validation acc: 56.20 - Saved the best model\n",
      "[4] train acc: 58.90, validation acc: 64.20 - Saved the best model\n",
      "[10] train acc: 91.40, validation acc: 56.00\n",
      "[12] train acc: 93.60, validation acc: 66.60 - Saved the best model\n",
      "[14] train acc: 95.90, validation acc: 71.50 - Saved the best model\n",
      "[20] train acc: 98.50, validation acc: 64.10\n",
      "[30] train acc: 99.50, validation acc: 56.70\n",
      "[40] train acc: 99.90, validation acc: 52.50\n",
      "[50] train acc: 99.70, validation acc: 57.90\n",
      "[58] train acc: 100.00, validation acc: 72.10 - Saved the best model\n",
      "[60] train acc: 99.90, validation acc: 70.80\n",
      "[70] train acc: 99.90, validation acc: 57.60\n",
      "[76] train acc: 99.60, validation acc: 72.60 - Saved the best model\n",
      "[80] train acc: 99.90, validation acc: 66.90\n",
      "[85] train acc: 98.90, validation acc: 72.90 - Saved the best model\n",
      "[90] train acc: 99.60, validation acc: 66.90\n",
      "[92] train acc: 99.30, validation acc: 75.70 - Saved the best model\n",
      "[100] train acc: 99.50, validation acc: 65.30\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for epoch in range(101):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for traindata in trainloader: \n",
    "       \n",
    "        inputs, labels = traindata[0].to(device), traindata[1].to(device)     \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = accuracy(valloader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './models/cifar_model_for_pseudo_baseline.pth')  \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('./models/cifar_model_for_pseudo_baseline.pth'))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측값을 기준으로하는 의사라벨과 예측값을 비교하여 손실 함수를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device) # 모델 선언\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  반지도 학습(Semi-Supervised Learning)의 일종인 \"일관성 정규화(Consistency Regularization)\"\n",
    "\n",
    "1. unlabeledloader에서 비지도 학습 데이터인 \"의사 레이블(pseudo-label)\"을 사용합니다.\n",
    "2. 모델의 출력과 의사 레이블 간의 일관성을 유지하기 위해 손실 함수에 추가적인 항 (alpha * criterion(poutputs, plabels))을 사용합니다.\n",
    "3. T1 에폭 이후부터 T2 에폭까지 alpha 값을 선형적으로 증가시킵니다. 이것은 일관성 정규화의 가중치를 조절하는 데 사용됩니다.\n",
    "\n",
    "alpha 값(즉, pseudo-labeled data의 중요도)에 따라 loss 계산 방식이 달라집니다. alpha가 0보다 큰 경우에만 pseudo-labeled data의 loss가 포함되며, 그렇지 않은 경우 labeled data만으로 loss를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 17.30, validation acc: 26.90 - Saved the best model\n",
      "[1] train acc: 31.40, validation acc: 48.50 - Saved the best model\n",
      "[3] train acc: 54.80, validation acc: 48.50 - Saved the best model\n",
      "[4] train acc: 68.90, validation acc: 51.20 - Saved the best model\n",
      "[10] train acc: 93.70, validation acc: 42.70\n",
      "[20] train acc: 99.30, validation acc: 35.00\n",
      "[30] train acc: 100.00, validation acc: 33.10\n",
      "[40] train acc: 100.00, validation acc: 35.00\n",
      "[50] train acc: 100.00, validation acc: 34.40\n",
      "[60] train acc: 99.80, validation acc: 36.80\n",
      "[70] train acc: 100.00, validation acc: 40.50\n",
      "[79] train acc: 99.60, validation acc: 56.70 - Saved the best model\n",
      "[80] train acc: 99.60, validation acc: 43.60\n",
      "[84] train acc: 99.50, validation acc: 59.50 - Saved the best model\n",
      "[86] train acc: 99.70, validation acc: 60.20 - Saved the best model\n",
      "[87] train acc: 99.70, validation acc: 64.10 - Saved the best model\n",
      "[90] train acc: 99.90, validation acc: 51.00\n",
      "[100] train acc: 99.90, validation acc: 38.00\n"
     ]
    }
   ],
   "source": [
    "alpha = 0\n",
    "alpha_t = 1e-4\n",
    "T1 = 100\n",
    "T2 = 450\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(101):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for traindata, pseudodata in zip(trainloader, unlabeledloader): \n",
    "       \n",
    "        inputs, labels = traindata[0].to(device), traindata[1].to(device)     \n",
    "        pinputs = pseudodata[0].to(device) \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        if alpha > 0:            \n",
    "            poutputs = model(pinputs)  \n",
    "            _, plabels = torch.max(poutputs.detach(), 1)     \n",
    "            loss = criterion(outputs, labels)  + alpha * criterion(poutputs, plabels)   \n",
    "        else:    \n",
    "            loss = criterion(outputs, labels)    \n",
    "              \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    if (epoch > T1) and (epoch < T2):\n",
    "        alpha = alpha_t*(epoch - T1)/(T2 - T1)\n",
    "    elif epoch >= T2:    \n",
    "        alpha = alpha_t\n",
    "\n",
    "    val_acc = accuracy(valloader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './models/cifar_model_for_pseudo_label.pth')    \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.47"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('./models/cifar_model_for_pseudo_label.pth'))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터로만 학습한 모델을 가지고 의사라벨을 만들어 데이터로 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device) # 모델 선언\n",
    "model.load_state_dict(torch.load('./models/cifar_model_for_pseudo_baseline.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:10<00:00, 22.63it/s]\n"
     ]
    }
   ],
   "source": [
    "pseudo_threshold = 0.99\n",
    "pseudo_images = torch.tensor([], dtype=torch.float)\n",
    "pseudo_labels = torch.tensor([], dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(unlabeledloader):\n",
    "        model.eval()\n",
    "        images = data[0].to(device)\n",
    "        outputs = model(images)\n",
    "        #print(outputs.size())\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        max_val, predicted = torch.max(outputs.detach(), 1)\n",
    "        idx = np.where(max_val.cpu().numpy() >= pseudo_threshold)[0]\n",
    "        if len(idx) > 0:\n",
    "            pseudo_images = torch.cat((pseudo_images, images.cpu()[idx]), 0) \n",
    "            pseudo_labels = torch.cat((pseudo_labels, predicted.cpu()[idx]), 0)\n",
    "\n",
    "#print(pseudo_images.size(), pseudo_labels.size())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57911, 1, 28, 28]) torch.Size([57911])\n"
     ]
    }
   ],
   "source": [
    "print(pseudo_images.size(), pseudo_labels.size())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_dataset = MyDataset(pseudo_images, pseudo_labels)\n",
    "pseudoloader = torch.utils.data.DataLoader(pseudo_dataset, batch_size=256, shuffle=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " alpha 값과 관계없이 항상 labeled data와 pseudo-labeled data 모두에 대한 loss를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train acc: 99.70, validation acc: 59.80 - Saved the best model\n",
      "[1] train acc: 99.30, validation acc: 66.50 - Saved the best model\n",
      "[2] train acc: 99.80, validation acc: 80.40 - Saved the best model\n",
      "[10] train acc: 99.40, validation acc: 64.30\n",
      "[20] train acc: 99.50, validation acc: 63.00\n",
      "[26] train acc: 99.60, validation acc: 80.40 - Saved the best model\n",
      "[30] train acc: 99.80, validation acc: 80.60 - Saved the best model\n",
      "[40] train acc: 99.70, validation acc: 75.70\n",
      "[50] train acc: 99.70, validation acc: 57.70\n",
      "[60] train acc: 99.40, validation acc: 58.70\n",
      "[70] train acc: 99.70, validation acc: 46.40\n",
      "[80] train acc: 100.00, validation acc: 39.70\n",
      "[90] train acc: 99.90, validation acc: 31.00\n",
      "[100] train acc: 99.90, validation acc: 32.40\n"
     ]
    }
   ],
   "source": [
    "alpha = 0\n",
    "alpha_t = 1e-4\n",
    "T1 = 20\n",
    "T2 = 450\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(101):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for traindata, pseudodata in zip(trainloader, pseudoloader): \n",
    "       \n",
    "        inputs, labels = traindata[0].to(device), traindata[1].to(device)     \n",
    "        pinputs, plabels = pseudodata[0].to(device), pseudodata[1].to(device)    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        poutputs = model(pinputs)\n",
    "        loss = criterion(outputs, labels) + alpha*criterion(poutputs, plabels)         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.detach(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #scheduler.step()\n",
    "    if (epoch > T1) and (epoch < T2):\n",
    "        alpha = alpha_t*(epoch - T1)/(T2 - T1)\n",
    "        \n",
    "    elif epoch >= T2:    \n",
    "        alpha = alpha_t\n",
    "\n",
    "    val_acc = accuracy(valloader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './models/cifar_model_for_pseudo_label2.pth') \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.94"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('./models/cifar_model_for_pseudo_label2.pth'))\n",
    "accuracy(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
